{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install google-api-python-client"
      ],
      "metadata": {
        "id": "jiR4OzF5REJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get list of all the video urls on a yt channel"
      ],
      "metadata": {
        "id": "oVrk01SLO3cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### search for externalId in the source code to find channel id\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def get_video_urls(channel_id, api_key):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "    video_urls = []\n",
        "\n",
        "    # Fetch the uploads playlist ID for the channel\n",
        "    request = youtube.channels().list(part='contentDetails', id=channel_id)\n",
        "    response = request.execute()\n",
        "    playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "    # Fetch all videos in the uploads playlist\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        pl_request = youtube.playlistItems().list(\n",
        "            part='contentDetails',\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        pl_response = pl_request.execute()\n",
        "\n",
        "        video_ids = [item['contentDetails']['videoId'] for item in pl_response['items']]\n",
        "        video_urls.extend([f'https://www.youtube.com/watch?v={id}' for id in video_ids])\n",
        "\n",
        "        next_page_token = pl_response.get('nextPageToken')\n",
        "\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_urls\n",
        "\n",
        "def save_urls_to_file(urls, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        for url in urls:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "# Replace with your API key and the channel ID you're interested in\n",
        "api_key = ''\n",
        "channel_id = ''\n",
        "filename = 'file1.txt'\n",
        "\n",
        "video_urls = get_video_urls(channel_id, api_key)\n",
        "save_urls_to_file(video_urls, filename)\n"
      ],
      "metadata": {
        "id": "vl_5WoPOaqI7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get transcripts of videos"
      ],
      "metadata": {
        "id": "Zjfjk61UPCDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "13dsATeHQv4L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# pip install youtube-transcript-api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def read_urls_from_file(file_path: Path) -> List[str]:\n",
        "    \"\"\"\n",
        "    Reads URLs from a text file and returns them as a list.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read().splitlines()\n",
        "\n",
        "def get_youtube_video_id_from_url(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts and returns the video ID from the given YouTube URL.\n",
        "    \"\"\"\n",
        "    query_string = urlparse(url).query\n",
        "    parameters = parse_qs(query_string)\n",
        "    return parameters.get('v', [None])[0]\n",
        "\n",
        "def get_youtube_video_transcript(video_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns transcript of the given 'video_id'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(\n",
        "            video_id, languages=['en-US', 'en']\n",
        "        )\n",
        "        utterances = [p['text'] for p in transcript]\n",
        "        return ' '.join(utterances)\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\\nCould not retrieve a transcript: \" + str(e)  # Return the exception message with a prefix\n",
        "\n",
        "def save_transcript(transcript: str, video_id: str, directory: Path):\n",
        "    \"\"\"\n",
        "    Stores the transcript locally in a text file named after the video ID.\n",
        "    \"\"\"\n",
        "    file_path = directory / f'{video_id}.txt'  # Create file path with video ID\n",
        "\n",
        "    # Skip saving if the transcript starts with the error message\n",
        "    if transcript.startswith(\"\\n\"):\n",
        "        return\n",
        "\n",
        "    if transcript is not None:\n",
        "        with open(file_path, 'w') as output_file:\n",
        "            output_file.write(transcript)\n",
        "\n",
        "# Specify the directory for saving the transcripts and the file containing the URLs\n",
        "urls_file_path = Path('/content/file1.txt') # Replace with the path to your file\n",
        "output_directory = Path('/content/data') # Specify the directory for saving transcripts\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "urls = read_urls_from_file(urls_file_path)\n",
        "\n",
        "for url in urls:\n",
        "    video_id = get_youtube_video_id_from_url(url)\n",
        "\n",
        "    if video_id:\n",
        "        transcript = get_youtube_video_transcript(video_id)\n",
        "        save_transcript(transcript, video_id, output_directory)\n",
        "    else:\n",
        "        print(f\"Invalid YouTube URL: {url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To zip the folder"
      ],
      "metadata": {
        "id": "GD8gVZhpOrfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/MarkBell.zip /content/MarkBell"
      ],
      "metadata": {
        "id": "gj1c3azfhJBy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To delete the folder"
      ],
      "metadata": {
        "id": "jFA5kELVOyD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/MarkBell', ignore_errors=True)\n"
      ],
      "metadata": {
        "id": "8raU2zd45hpa"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}